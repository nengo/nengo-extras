{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classifier with Keras and Nengo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Convolution2D, Dense, Dropout, Flatten\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "from nengo_extras.keras import (\n",
    "    load_model_pair,\n",
    "    save_model_pair,\n",
    "    SequentialNetwork,\n",
    "    SoftLIF,\n",
    ")\n",
    "from nengo_extras.gui import image_display_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters\n",
    "np.random.seed(1)\n",
    "filename = \"mnist_spiking_cnn\"\n",
    "use_dl = True\n",
    "presentation_time = 0.1\n",
    "n_presentations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data\n",
    "img_rows, img_cols = 28, 28\n",
    "n_classes = 10\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "data_format = \"channels_first\"\n",
    "\n",
    "\n",
    "def preprocess(X):\n",
    "    X = X.astype(\"float32\") / 128 - 1\n",
    "    if data_format == \"channels_first\":\n",
    "        X = X.reshape((X.shape[0], 1, img_rows, img_cols))\n",
    "    else:\n",
    "        X = X.reshape((X.shape[0], img_rows, img_cols, 1))\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "X_train, X_test = preprocess(X_train), preprocess(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train model\n",
    "if not os.path.exists(filename + \".h5\"):\n",
    "    batch_size = 128\n",
    "    epochs = 6\n",
    "\n",
    "    n_filters = 32  # number of convolutional filters to use\n",
    "    kernel_size = (3, 3)  # shape of each convolutional filter\n",
    "\n",
    "    softlif_params = dict(sigma=0.01, amplitude=0.063, tau_rc=0.022, tau_ref=0.002)\n",
    "\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "    # construct Keras model\n",
    "    kmodel = Sequential()\n",
    "    kmodel.add(GaussianNoise(0.1, input_shape=input_shape))\n",
    "\n",
    "    kmodel.add(\n",
    "        Convolution2D(\n",
    "            n_filters,\n",
    "            kernel_size,\n",
    "            padding=\"valid\",\n",
    "            strides=(2, 2),\n",
    "            data_format=data_format,\n",
    "        )\n",
    "    )\n",
    "    kmodel.add(SoftLIF(**softlif_params))\n",
    "\n",
    "    kmodel.add(\n",
    "        Convolution2D(n_filters, kernel_size, strides=(2, 2), data_format=data_format)\n",
    "    )\n",
    "    kmodel.add(SoftLIF(**softlif_params))\n",
    "\n",
    "    kmodel.add(Flatten())\n",
    "    kmodel.add(Dense(512))\n",
    "    kmodel.add(SoftLIF(**softlif_params))\n",
    "    kmodel.add(Dropout(0.5))\n",
    "\n",
    "    kmodel.add(Dense(n_classes))\n",
    "    kmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "    # compile and fit Keras model\n",
    "    optimizer = tf.keras.optimizers.Nadam()\n",
    "    kmodel.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    kmodel.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, Y_test),\n",
    "    )\n",
    "\n",
    "    score = kmodel.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Test score:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "\n",
    "    save_model_pair(kmodel, filename, overwrite=True)\n",
    "\n",
    "else:\n",
    "    kmodel = load_model_pair(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run model in Nengo\n",
    "with nengo.Network() as model:\n",
    "    u = nengo.Node(nengo.processes.PresentInput(X_test, presentation_time))\n",
    "    knet = SequentialNetwork(kmodel, synapse=nengo.synapses.Alpha(0.005))\n",
    "    nengo.Connection(u, knet.input, synapse=None)\n",
    "\n",
    "    input_p = nengo.Probe(u)\n",
    "    output_p = nengo.Probe(knet.output)\n",
    "\n",
    "    # --- image display\n",
    "    image_shape = kmodel.input_shape[1:]\n",
    "    display_f = image_display_function(image_shape)\n",
    "    display_node = nengo.Node(display_f, size_in=u.size_out)\n",
    "    nengo.Connection(u, display_node, synapse=None)\n",
    "\n",
    "    # --- output spa display\n",
    "    vocab_names = [\n",
    "        \"ZERO\",\n",
    "        \"ONE\",\n",
    "        \"TWO\",\n",
    "        \"THREE\",\n",
    "        \"FOUR\",\n",
    "        \"FIVE\",\n",
    "        \"SIX\",\n",
    "        \"SEVEN\",\n",
    "        \"EIGHT\",\n",
    "        \"NINE\",\n",
    "    ]\n",
    "    vocab_vectors = np.eye(len(vocab_names))\n",
    "\n",
    "    vocab = nengo.spa.Vocabulary(len(vocab_names))\n",
    "    for name, vector in zip(vocab_names, vocab_vectors):\n",
    "        vocab.add(name, vector)\n",
    "\n",
    "    config = nengo.Config(nengo.Ensemble)\n",
    "    config[nengo.Ensemble].neuron_type = nengo.Direct()\n",
    "    with config:\n",
    "        output = nengo.spa.State(len(vocab_names), subdimensions=10, vocab=vocab)\n",
    "    nengo.Connection(knet.output, output.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim = nengo_dl.Simulator if use_dl else nengo.Simulator\n",
    "\n",
    "with Sim(model) as sim:\n",
    "    sim.run(n_presentations * presentation_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = int(presentation_time / sim.dt)\n",
    "blocks = sim.data[output_p].reshape((n_presentations, nt, n_classes))\n",
    "choices = np.argmax(blocks[:, -20:, :].mean(axis=1), axis=1)\n",
    "accuracy = (choices == y_test[:n_presentations]).mean()\n",
    "print(\"Spiking accuracy (%d examples): %0.3f\" % (n_presentations, accuracy))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
