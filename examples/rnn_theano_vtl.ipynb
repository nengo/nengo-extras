{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import nengo\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio\n",
    "\n",
    "import nengo_deeplearning.backends.theano.optimizers as opt\n",
    "import nengo_deeplearning.processes as proc\n",
    "from nengo_deeplearning.backends.theano.networks import RNN\n",
    "from nengo_deeplearning.backends.theano.layers import Generic, GatedRecurrent, LstmRecurrent, Dense\n",
    "from skspeech import vtl\n",
    "from skspeech import audio as skaudio\n",
    "import skspeech\n",
    "\n",
    "# Let's try all of the German CV gestures...\n",
    "zippath = skspeech.data_path('ges-de-v.zip')\n",
    "speaker = vtl.VTL.default_speaker\n",
    "\n",
    "root = os.getcwd()\n",
    "gesdir = os.path.join(root, 'ges')\n",
    "wavdir = os.path.join(root, 'wav')\n",
    "txtdir = os.path.join(root, 'txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    with ZipFile(zippath) as zf:\n",
    "        zf.extractall(path=gesdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an RNN to decode VTGs from synthesized utterances\n",
    "\n",
    "Notes:\n",
    "\n",
    "- [Lasagne](http://lasagne.readthedocs.org/en/latest/user/tutorial.html)\n",
    "- [HF2Nengo](https://github.com/nengo/nengo_deeplearning/pull/2)\n",
    "\n",
    "CTC notes:\n",
    "\n",
    "- [Blog post](http://andrew.gibiansky.com/blog/machine-learning/speech-recognition-neural-networks/)\n",
    "- [pure Theano](https://github.com/mohammadpz/CTC-Connectionist-Temporal-Classification)\n",
    "- [Lasagne](https://github.com/skaae/Lasagne-CTC/blob/master/ctc_cost.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 0.02\n",
    "audio_f = skaudio.mfcc\n",
    "audio_fargs = {'maxfreq': 2000,\n",
    "               'preemph': 0,\n",
    "               'energy': False,\n",
    "               'remove_0': True,}\n",
    "\n",
    "trX, trY = [], []\n",
    "for gesfile in os.listdir(gesdir):\n",
    "    gespath = os.path.join(gesdir, gesfile)\n",
    "    wavpath = os.path.join(wavdir, \"%s.wav\" % gesfile[:-4])\n",
    "    x, y, fs = vtl.get_traindata(gespath, audio_f, dt, audio_fargs, wavpath)\n",
    "    trX.append(x), trY.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot two random X feature trajectories\n",
    "ix = range(len(trX))\n",
    "random.shuffle(ix)\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(trX[ix[0]].T[1:])\n",
    "plt.title(\"trX[%d]\" % ix[0])\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(trX[ix[1]].T[1:])\n",
    "plt.title(\"trX[%d]\" % ix[1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the corresponding gesture trajectories\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(trY[ix[0]].T)\n",
    "plt.title(\"trY[%d]\" % ix[0])\n",
    "plt.ylim(49, 0)\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(trY[ix[1]].T)\n",
    "plt.title(\"trY[%d]\" % ix[1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assemble the individual examples into training examples\n",
    "n_cepstrum = trX[0].shape[1]\n",
    "trX = np.concatenate(trX)[:, np.newaxis, :]\n",
    "print trX.shape\n",
    "\n",
    "# Delay the y by some ms\n",
    "delay = int(0.04 * fs * dt)\n",
    "print \"delay frames: %d\" % delay\n",
    "trY = np.concatenate(trY)\n",
    "trY = np.roll(trY, delay, axis=0)\n",
    "trY[:delay] = 0.\n",
    "print trY.shape\n",
    "\n",
    "assert trX.shape[0] == trY.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a gesture score\n",
    "trajs = []\n",
    "\n",
    "dt = 0.02\n",
    "gs = skspeech.vtl.parse_ges('ges-de-cvc/das.ges')\n",
    "print gs.t_end\n",
    "traj = gs.trajectory(dt=dt)\n",
    "# For dot products, we change this slighty\n",
    "# so that non-gestures are -1, gestures are 1\n",
    "traj[traj > 0] = 2.\n",
    "traj -= 1.\n",
    "trajs.append(traj)\n",
    "\n",
    "plt.pcolormesh(traj.T)\n",
    "plt.colorbar()\n",
    "traj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a gesture score\n",
    "dt = 0.02\n",
    "gs = skspeech.vtl.parse_ges('ges-de-cvc/bak.ges')\n",
    "print gs.t_end\n",
    "traj = gs.trajectory(dt=dt)\n",
    "# For dot products, we change this slighty\n",
    "# so that non-gestures are -1, gestures are 1\n",
    "traj[traj > 0] = 2.\n",
    "traj -= 1.\n",
    "trajs.append(traj)\n",
    "\n",
    "plt.pcolormesh(traj.T)\n",
    "plt.colorbar()\n",
    "traj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX = np.concatenate(trajs)\n",
    "trX = trX[:, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trY = np.zeros((trX.shape[0], len(trajs)))\n",
    "ix = 0\n",
    "for i, traj in enumerate(trajs):\n",
    "    l = traj.shape[0]\n",
    "    trY[ix:ix+l, i] = 1.\n",
    "    ix += l\n",
    "trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Generic(size=trX.shape[2]),\n",
    "    GatedRecurrent(size=256, p_drop=0.2),\n",
    "    Dense(size=trY.shape[1], activation='softmax', p_drop=0.5),\n",
    "]\n",
    "\n",
    "# A bit of l2 helps with generalization, higher momentum helps convergence\n",
    "optimizer = opt.NAG(momentum=0.95, regularizer=opt.Regularizer(l2=1e-4))\n",
    "\n",
    "# Linear iterator for real valued data, cce cost for softmax\n",
    "model = RNN(layers=layers, optimizer=optimizer, iterator='linear', cost='cce')\n",
    "model.fit(trX, trY, n_epochs=500)\n",
    "\n",
    "tr_preds = model.predict(trX)  # [:len(teY)])\n",
    "# te_preds = model.predict(teX)\n",
    "\n",
    "tr_acc = np.mean(np.argmax(trY, axis=1) == np.argmax(tr_preds, axis=1))\n",
    "# tr_acc = np.sqrt(np.mean((trY - tr_preds) ** 2))\n",
    "# te_acc = np.mean(np.argmax(teY, axis=1) == np.argmax(te_preds, axis=1))\n",
    "\n",
    "print \"  ====== Results ======\"\n",
    "# print \"Train accuracy %s\\tTest accuracy %s\" % (tr_acc, te_acc)\n",
    "print \"Train accuracy %s\" % tr_acc\n",
    "# model.save('trained_rnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st, end = 0, -1\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(trY[st:end])\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(tr_preds[st:end])\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(tr_preds[st:end] - trY[st:end]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
