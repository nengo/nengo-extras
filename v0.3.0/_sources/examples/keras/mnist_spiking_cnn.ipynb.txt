{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classifier with Keras and Nengo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import nengo\n",
    "import nengo_ocl\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Activation, Convolution2D, Dense, Dropout, Flatten)\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from nengo_extras.keras import (\n",
    "    load_model_pair, save_model_pair, SequentialNetwork, SoftLIF)\n",
    "from nengo_extras.gui import image_display_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters\n",
    "np.random.seed(1)\n",
    "filename = 'mnist_spiking_cnn'\n",
    "run_in_theano = False\n",
    "use_ocl = True\n",
    "presentation_time = 0.15\n",
    "n_presentations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data\n",
    "img_rows, img_cols = 28, 28\n",
    "n_classes = 10\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "data_format = 'channels_first'\n",
    "\n",
    "\n",
    "def preprocess(X):\n",
    "    X = X.astype('float32') / 128 - 1\n",
    "    if data_format == 'channels_first':\n",
    "        X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    else:\n",
    "        X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "X_train, X_test = preprocess(X_train), preprocess(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train model\n",
    "if not os.path.exists(filename + '.h5'):\n",
    "    batch_size = 128\n",
    "    epochs = 6\n",
    "\n",
    "    n_filters = 32        # number of convolutional filters to use\n",
    "    kernel_size = (3, 3)  # shape of each convolutional filter\n",
    "\n",
    "    softlif_params = dict(\n",
    "        sigma=0.01, amplitude=0.063, tau_rc=0.022, tau_ref=0.002)\n",
    "\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "    # construct Keras model\n",
    "    kmodel = Sequential()\n",
    "    kmodel.add(GaussianNoise(0.1, input_shape=input_shape))\n",
    "\n",
    "    kmodel.add(Convolution2D(n_filters, kernel_size, padding='valid',\n",
    "                             strides=(2, 2),\n",
    "                             data_format=data_format))\n",
    "    kmodel.add(SoftLIF(**softlif_params))\n",
    "\n",
    "    kmodel.add(Convolution2D(n_filters, kernel_size,\n",
    "                             strides=(2, 2),\n",
    "                             data_format=data_format))\n",
    "    kmodel.add(SoftLIF(**softlif_params))\n",
    "\n",
    "    kmodel.add(Flatten())\n",
    "    kmodel.add(Dense(512))\n",
    "    kmodel.add(SoftLIF(**softlif_params))\n",
    "    kmodel.add(Dropout(0.5))\n",
    "\n",
    "    kmodel.add(Dense(n_classes))\n",
    "    kmodel.add(Activation('softmax'))\n",
    "\n",
    "    # compile and fit Keras model\n",
    "    optimizer = keras.optimizers.Nadam()\n",
    "    kmodel.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=optimizer,\n",
    "                   metrics=['accuracy'])\n",
    "    kmodel.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "               verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "    score = kmodel.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    save_model_pair(kmodel, filename, overwrite=True)\n",
    "\n",
    "else:\n",
    "    kmodel = load_model_pair(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run model in Nengo\n",
    "with nengo.Network() as model:\n",
    "    u = nengo.Node(nengo.processes.PresentInput(X_test, presentation_time))\n",
    "    knet = SequentialNetwork(kmodel, synapse=nengo.synapses.Alpha(0.005))\n",
    "    nengo.Connection(u, knet.input, synapse=None)\n",
    "\n",
    "    input_p = nengo.Probe(u)\n",
    "    output_p = nengo.Probe(knet.output)\n",
    "\n",
    "    # --- image display\n",
    "    image_shape = kmodel.input_shape[1:]\n",
    "    display_f = image_display_function(image_shape)\n",
    "    display_node = nengo.Node(display_f, size_in=u.size_out)\n",
    "    nengo.Connection(u, display_node, synapse=None)\n",
    "\n",
    "    # --- output spa display\n",
    "    vocab_names = ['ZERO', 'ONE', 'TWO', 'THREE', 'FOUR',\n",
    "                   'FIVE', 'SIX', 'SEVEN', 'EIGHT', 'NINE']\n",
    "    vocab_vectors = np.eye(len(vocab_names))\n",
    "\n",
    "    vocab = nengo.spa.Vocabulary(len(vocab_names))\n",
    "    for name, vector in zip(vocab_names, vocab_vectors):\n",
    "        vocab.add(name, vector)\n",
    "\n",
    "    config = nengo.Config(nengo.Ensemble)\n",
    "    config[nengo.Ensemble].neuron_type = nengo.Direct()\n",
    "    with config:\n",
    "        output = nengo.spa.State(\n",
    "            len(vocab_names), subdimensions=10, vocab=vocab)\n",
    "    nengo.Connection(knet.output, output.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_theano:\n",
    "    os.environ['THEANO_FLAGS'] = 'device=gpu,floatX=float32'\n",
    "    Q = knet.theano_compute(X_test[:n_presentations])\n",
    "    Z = np.argmax(Q, axis=-1) == y_test[:n_presentations]\n",
    "    print(\"ANN accuracy (%d examples): %0.3f\" % (n_presentations, Z.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim = nengo_ocl.Simulator if use_ocl else nengo.Simulator\n",
    "\n",
    "with Sim(model) as sim:\n",
    "    sim.run(n_presentations * presentation_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = int(presentation_time / sim.dt)\n",
    "blocks = sim.data[output_p].reshape(n_presentations, nt, n_classes)\n",
    "choices = np.argmax(blocks[:, -20:, :].mean(axis=1), axis=1)\n",
    "accuracy = (choices == y_test[:n_presentations]).mean()\n",
    "print('Spiking accuracy (%d examples): %0.3f' % (n_presentations, accuracy))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
